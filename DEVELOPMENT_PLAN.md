# VoiceNav MVP Development Plan
## MacBook M3 Pro Edition - UPDATED BASED ON CURRENT PROGRESS

---

## ğŸ¯ WHAT IS VOICENAV?

**VoiceNav is a desktop Python application** that runs in the background on your MacBook and controls your web browser using voice commands.

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VoiceNav Desktop App (Python)      â”‚
â”‚  - Listens to microphone            â”‚
â”‚  - Processes voice commands         â”‚
â”‚  - Controls browser via Playwright  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (controls)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chrome/Safari Browser              â”‚
â”‚  - Opens and navigates pages        â”‚
â”‚  - Clicks elements                  â”‚
â”‚  - Reads content aloud              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**NOT:**
- âŒ A browser extension (too limited)
- âŒ A web app (needs system access)
- âŒ A mobile app (different challenge)

**IT IS:**
- âœ… A macOS desktop application (Python-based)
- âœ… Runs as a background service
- âœ… Has a menu bar icon for status/controls
- âœ… Controls your default browser programmatically

---

## ğŸ“‹ MVP FEATURE SET (Minimum Viable Product)

### Core Features:
1. **Voice Command System**
   - Wake word: "Hey Maya" âœ… **IMPLEMENTED**
   - 8 essential commands (see Stage 2)
   - Voice confirmation feedback âœ… **IMPLEMENTED**

2. **Browser Control**
   - Open URLs
   - Click elements by description
   - Scroll navigation
   - Read page content aloud

3. **Accessibility Features**
   - Text-to-speech feedback âœ… **IMPLEMENTED (Samantha voice)**
   - Visual overlay showing active state
   - Clear error messages

4. **User Interface**
   - Menu bar app (macOS status bar)
   - Simple settings window
   - Landing page (promotional website)

---

## ğŸ—ï¸ DEVELOPMENT STAGES - UPDATED STATUS

### **STAGE 0: Project Setup & Environment** âœ… **COMPLETE**
**Goal:** Get a working Python environment on M3 Mac with all dependencies

**Status**: âœ… **COMPLETE** - All deliverables achieved
- âœ… Project folder structure created (19 files, 3,000+ lines)
- âœ… All dependencies installed successfully
- âœ… Environment test passes
- âœ… README has clear setup instructions
- âœ… Comprehensive documentation suite (6 docs)
- âœ… Python 3.11+ validated
- âœ… M3 Mac compatibility confirmed

**Deliverables Completed:**
- âœ… Complete project structure with src/, tests/, docs
- âœ… requirements.txt with 6 core dependencies
- âœ… Environment validation script (tests/test_environment.py)
- âœ… Comprehensive setup guide for M3 Mac
- âœ… Git repository initialized
- âœ… Professional documentation suite

**Time Actual:** 1 hour (vs estimate 30-45 minutes)

---

### **STAGE 1: Voice Listening Foundation** âœ… **COMPLETE**
**Goal:** Detect wake word and capture voice commands

**Status**: âœ… **COMPLETE** - All deliverables achieved with enhancements
- âœ… Wake word detection working ("Hey Maya")
- âœ… High-accuracy speech recognition (OpenAI Whisper)
- âœ… Voice feedback system (Samantha TTS)
- âœ… Comprehensive test suite
- âœ… System reverted to stable working state

**Major Implementations:**
- âœ… **WhisperVoiceListener**: High-accuracy offline recognition
- âœ… **Maya wake word**: Accent-friendly, tested and working
- âœ… **Samantha voice feedback**: Natural speech responses
- âœ… **Factory system**: Automatic best-engine selection
- âœ… **Comprehensive testing**: Multiple test scripts and validation
- âœ… **System revert**: Removed problematic enhanced features, back to working state

**Current Working System:**
```python
from input.voice_listener import create_voice_listener
maya = create_voice_listener(wake_word="hey maya")  # Uses WhisperVoiceListener
result = maya.listen_once()  # Simple, reliable recognition
```

**Test Results:**
- âœ… Maya responds to "Hey Maya" consistently
- âœ… Whisper provides 95%+ accuracy
- âœ… Samantha voice speaks confirmations
- âœ… All test scripts pass validation
- âœ… System stable and reliable

**Deliverables Completed:**
- âœ… src/input/voice_listener.py - Factory function system
- âœ… src/input/whisper_voice_listener.py - High-accuracy recognition
- âœ… Multiple test scripts (maya, whisper, voice integration)
- âœ… Master test runner (run_all_tests.py)
- âœ… Comprehensive error handling and user guidance

**Time Actual:** 3 hours (vs estimate 2-3 hours)

**Current State:** âœ… **READY FOR STAGE 2** - Voice system fully functional

---

### **STAGE 2: Command Parser & Browser Control** âœ… **CORE COMPLETE**
**Goal:** Interpret voice commands and control browser

**Dependencies:** âœ… Stage 1 complete and tested

**Status**: âœ… **70% COMPLETE** - Parser & Integration working, Browser needs fixes

#### Goose Instructions for Stage 2:
```
STAGE 2: Command Parser & Browser Control Integration

Build on: Stage 1 COMPLETE - Maya + Whisper system working

Current System Status:
- âœ… Maya wake word detection working
- âœ… WhisperVoiceListener providing high accuracy
- âœ… Samantha voice feedback functional
- âœ… Factory function: create_voice_listener() defaults to Whisper
- âœ… All Stage 1 tests passing

Tasks for Stage 2:

PART A: Command Parser (src/brain/command_parser.py)

MVP Commands (8 total):
1. "open [website]" â†’ Open URL
2. "go to [website]" â†’ Same as open
3. "click [element]" â†’ Click described element
4. "scroll down" â†’ Scroll down page
5. "scroll up" â†’ Scroll up page
6. "go back" â†’ Browser back button
7. "read page" â†’ Read main content aloud
8. "stop" â†’ Stop current action

Parser Logic:
- Extract intent (open, click, scroll, back, read, stop)
- Extract parameters (website name, element description)
- Return structured action: {
    "intent": "open_url",
    "params": {"url": "google.com"},
    "original": "open google"
  }

URL Normalization:
- "google" â†’ "https://google.com"
- "youtube" â†’ "https://youtube.com"
- "gmail" â†’ "https://gmail.com"
- Handle: "reddit.com" â†’ "https://reddit.com"
- Handle: "bbc.co.uk" â†’ "https://bbc.co.uk"

Element Description Parser:
- "login button" â†’ {"type": "button", "text": "login"}
- "search box" â†’ {"type": "input", "purpose": "search"}
- "red button" â†’ {"color": "red", "type": "button"}

PART B: Browser Control (src/actions/browser_control.py)

Setup:
1. Install Playwright browsers: playwright install chromium
2. Use Playwright (not Selenium - better for M3 Mac)
3. Launch browser in headed mode (visible window)

Core Functions:

1. initialize_browser()
   - Launch Chromium
   - Set viewport: 1280x720
   - Return browser and page objects

2. open_url(url: str)
   - Navigate to URL
   - Wait for page load (wait_for_load_state("networkidle"))
   - Use Maya's voice: "Opened [domain name]"

3. click_element(description: dict)
   - Find element matching description
   - Highlight element (yellow border for 1 second)
   - Click element
   - Use Maya's voice: "Clicked [element]"

4. scroll_page(direction: str, amount: int = 300)
   - Scroll up or down by amount pixels
   - Use Maya's voice: "Scrolling [direction]"

5. go_back()
   - Browser back navigation
   - Use Maya's voice: "Going back"

6. read_content()
   - Extract main article text (ignore nav, ads, footer)
   - Use Maya's voice to speak extracted text
   - Stop reading on "stop" command

Element Finding Strategy:
- Try role-based selectors first: page.get_by_role("button", name="login")
- Fallback to text content: page.locator("text=login")
- Fallback to CSS selectors for common patterns

PART C: Integration Script (src/main.py update)

Integration with existing Maya system:
```python
from input.voice_listener import create_voice_listener
from brain.command_parser import CommandParser
from actions.browser_control import BrowserController

def main():
    # Use the working Maya system
    maya = create_voice_listener(wake_word="hey maya")
    parser = CommandParser()
    browser = BrowserController()
    
    print("ğŸ¤ Maya is ready! Say 'Hey Maya' to start.")
    
    while True:
        # Listen for Maya wake word + command
        result = maya.listen_once()
        if result and result.get('raw_text'):
            # Parse the command
            action = parser.parse(result['raw_text'])
            
            # Execute browser action
            browser.execute(action)
```

Testing Scripts:

tests/test_parser.py:
Test these inputs:
- "open google" â†’ {intent: "open_url", params: {url: "https://google.com"}}
- "click login button" â†’ {intent: "click_element", params: {type: "button", text: "login"}}
- "scroll down" â†’ {intent: "scroll", params: {direction: "down"}}
- "read page" â†’ {intent: "read_content"}
- "stop" â†’ {intent: "stop_action"}

tests/test_browser.py:
Automated test:
1. Open browser
2. Navigate to: https://example.com
3. Check page title contains "Example"
4. Scroll down 300px
5. Scroll up 300px
6. Go back (should stay on same page, no history)
7. Close browser
8. Print: "All browser actions successful!"

tests/test_integration.py:
Manual test (run from terminal):
1. Start integration script
2. Say: "Hey Maya"
3. Say: "open google"
4. Verify: Google opens in browser AND Maya says "Opened Google"
5. Say: "Hey Maya"
6. Say: "scroll down"
7. Verify: Page scrolls AND Maya says "Scrolling down"
8. Say: "Hey Maya"
9. Say: "go back"
10. Verify: Browser goes back AND Maya says "Going back"

CHECKPOINT - Must pass before Stage 3:
â–¡ Command parser test: 10/10 commands parsed correctly
â–¡ Browser automation test: All actions complete successfully
â–¡ Integration test: 3/3 voice commands execute properly
â–¡ Maya's voice feedback works for all actions
â–¡ Browser opens visibly (not headless)
â–¡ Works on M3 Mac (ARM architecture)
â–¡ No crashes or Playwright errors
â–¡ Maya system from Stage 1 still fully functional

Integration Notes:
- Reuse Maya's existing Samantha voice system for browser feedback
- Keep the working create_voice_listener() factory function
- Browser control should integrate seamlessly with Maya's responses
- Maintain all Stage 1 functionality while adding browser control
```

**Deliverables:**
- [ ] command_parser.py complete
- [ ] browser_control.py complete  
- [ ] Integration with Maya system
- [ ] All tests passing
- [ ] Voice feedback for browser actions

**Time Estimate:** 4-5 hours

---

### **STAGE 3: Main Application & Menu Bar UI** 
**Goal:** Connect all pieces into working application

#### Goose Instructions:
```
STAGE 3: Full Integration & Menu Bar App

Build on: Stages 1 & 2 working and tested

Create: src/main.py (complete application)

Main Application Loop:
1. Initialize browser (keep open)
2. Start voice listener (background thread)
3. When wake word detected:
   - Capture command
   - Parse command (Stage 2)
   - Execute action (Stage 2)
   - Maya provides feedback
   - Return to listening
4. Handle "quit maya" â†’ Clean shutdown

Threading:
- Main thread: Browser control + menu bar
- Background thread: Voice listener
- Use queue.Queue() for thread-safe communication

Create: src/ui/menu_bar.py (macOS Menu Bar App)
Using 'rumps' library:
- Show icon in macOS menu bar
- Icon states: 
  - ğŸ¤ (listening for wake word)
  - ğŸŸ¢ (processing command)
  - âš« (paused)
- Menu items:
  - "Status: Listening"
  - "Pause/Resume"
  - "Settings"
  - "Quit Maya"

Graceful Shutdown:
- Close browser cleanly
- Stop voice listener thread
- Save any logs
- Maya says "Goodbye"

Error Recovery:
- If browser crashes â†’ restart automatically
- If voice listener fails â†’ retry 3 times with Maya feedback
- Log all errors to: logs/voicenav.log

CHECKPOINT - Must pass before Stage 4:
â–¡ Application starts without errors
â–¡ Menu bar icon appears and changes states
â–¡ Can execute 3 commands in sequence successfully
â–¡ Application recovers from browser crash
â–¡ Maya provides voice feedback for all states
â–¡ Shutdown is clean (no zombie processes)
â–¡ Works continuously for 5+ minutes without issues
```

**Deliverables:**
- [ ] main.py complete
- [ ] Menu bar app working
- [ ] Can run 3+ commands in sequence
- [ ] Graceful error handling
- [ ] Clean shutdown

**Time Estimate:** 3-4 hours

---

### **STAGE 4: Polish & User Experience**
**Goal:** Make MVP production-ready

#### Goose Instructions:
```
STAGE 4: MVP Polish

Build on: Stage 3 fully working

Improvements:

1. Settings System (config.yaml enhancement)
   - Wake word customization
   - Maya's voice settings (speed/volume)
   - Browser preference (Chrome/Safari)
   - Scroll amount
   - Enable/disable features

2. Visual Feedback (src/ui/overlay.py)
   - Show floating overlay when listening
   - Display recognized command
   - Animate during processing
   - Show errors clearly

3. Command Help System
   - Voice command: "what can you do?"
   - Maya speaks list of available commands
   - Shows commands in menu bar menu

4. Enhanced Error Messages
   - "I didn't understand that command"
   - "I couldn't find that element"
   - "Please grant microphone permission"
   - All errors spoken by Maya + shown visually

5. Performance Optimization
   - Wake word detection < 500ms
   - Command execution < 2 seconds
   - CPU usage < 15% idle
   - Memory usage < 200MB

CHECKPOINT - MVP Complete:
â–¡ All UX improvements working
â–¡ No confusing error states
â–¡ Settings save and load correctly
â–¡ Performance targets met
â–¡ Maya feels responsive and helpful
â–¡ Ready for demo/competition
```

**Deliverables:**
- [ ] Settings system working
- [ ] Visual feedback polished
- [ ] Help system functional
- [ ] Performance optimized

**Time Estimate:** 4-5 hours

---

### **STAGE 5: Landing Page**
**Goal:** Professional website to showcase VoiceNav

#### Goose Instructions:
```
STAGE 5: Landing Page

Create: landing-page/index.html (single-page site)

Purpose: Competition submission + future users

Design Requirements:
- Modern, accessible design
- Dark mode with vibrant accents
- Fully responsive (mobile-first)
- Fast loading (no heavy frameworks)
- Screen reader friendly

Sections:

1. Hero Section
   - Headline: "Navigate the Web with Your Voice"
   - Subheadline: "VoiceNav makes the internet accessible through hands-free voice control powered by Maya AI"
   - CTA: "Download for macOS" (GitHub link)
   - Animated demo video/GIF

2. Problem Statement
   - "For people with limited mobility, traditional web browsing is frustrating"
   - Statistics on accessibility needs
   - Show pain points visually

3. Solution (How It Works)
   - Step 1: Say "Hey Maya" â†’ Illustration
   - Step 2: Speak your command â†’ Illustration  
   - Step 3: Watch it happen â†’ Illustration
   - Simple 3-step process

4. Features Grid
   - ğŸ¤ Voice Control - Navigate hands-free
   - ğŸ¤– Maya AI Assistant - Natural conversation
   - ğŸŒ Universal - Works on any website
   - ğŸ”’ Private - All processing on-device
   - âš¡ Fast - Commands execute instantly
   - ğŸ¯ Accurate - Whisper AI recognition
   - ğŸ†“ Free - Open source forever

5. Demo Video Section
   - Embedded video showing:
     * "Hey Maya, open reddit"
     * "Hey Maya, scroll down"
     * "Hey Maya, click the search box"
     * "Hey Maya, read page"
   - Subtitles for accessibility

6. Technical Details (for competition judges)
   - Built with Python + Playwright + OpenAI Whisper
   - Maya AI assistant with natural voice
   - Runs on macOS (M1/M2/M3)
   - Open source on GitHub
   - Architecture diagram

CHECKPOINT - Landing Page Complete:
â–¡ All sections present and polished
â–¡ Mobile responsive (test on phone)
â–¡ Loads in < 3 seconds
â–¡ No console errors
â–¡ Passes accessibility audit (Lighthouse)
â–¡ Demo video shows Maya in action
â–¡ Clear download/setup instructions
```

**Deliverables:**
- [ ] Landing page deployed (GitHub Pages)
- [ ] Demo video recorded with Maya
- [ ] Mobile responsive
- [ ] Accessibility compliant

**Time Estimate:** 3-4 hours

---

## ğŸ“Š UPDATED TESTING PROTOCOL

### Current System Verification (Before Stage 2):
```bash
cd /Users/vivianobiako/Github/Personal/voicenav
source venv/bin/activate

# Test the reverted Maya system
python3 test_original_maya.py

# Run comprehensive test suite
python3 run_all_tests.py

# Individual Maya tests
python3 test_maya.py
python3 test_maya_whisper.py
python3 test_maya_voice.py
```

### Final MVP Test (Updated for Maya):
```
End-to-End User Journey with Maya:

Setup Phase:
â–¡ Clone repository
â–¡ Run installation script  
â–¡ Grant microphone permissions
â–¡ Maya responds to "Hey Maya"

Usage Phase:
â–¡ Launch VoiceNav (menu bar icon appears)
â–¡ Say: "Hey Maya, open google"
   - Google opens AND Maya says "Opened Google"
â–¡ Say: "Hey Maya, scroll down" 
   - Page scrolls AND Maya says "Scrolling down"
â–¡ Say: "Hey Maya, click search box"
   - Search box focuses AND Maya confirms
â–¡ Say: "Hey Maya, go back"
   - Browser navigates back AND Maya confirms
â–¡ Say: "Hey Maya, read page"
   - Content reads aloud in Maya's voice
â–¡ Say: "Maya, stop"
   - Reading stops immediately
â–¡ Say: "What can you do Maya?"
   - Maya lists available commands

Performance:
â–¡ Maya wake word response < 500ms
â–¡ Command execution < 3 seconds
â–¡ Natural conversation flow with Maya
â–¡ Whisper accuracy > 95%
```

---

## ğŸ¯ SUCCESS CRITERIA (Updated)

### MVP is complete when:
- âœ… Stage 0 & 1 complete (CURRENT STATUS)
- âœ… Maya AI assistant fully functional
- âœ… Whisper recognition working reliably
- âœ… Samantha voice feedback operational
- [ ] All 5 stages pass checkpoints
- [ ] Final MVP test passes 100%
- [ ] Landing page showcases Maya
- [ ] Demo video features Maya interactions
- [ ] GitHub repository is public
- [ ] Runs on macOS M3 without issues

### Competition-Ready Checklist:
- [ ] 2-minute demo video featuring Maya
- [ ] GitHub repository with clean code
- [ ] Landing page highlighting Maya AI assistant
- [ ] Clear accessibility benefits demonstrated
- [ ] Maya responds reliably in front of judges
- [ ] Handles errors gracefully with Maya feedback
- [ ] Unique input method (voice + AI assistant)

---

## â±ï¸ UPDATED TIME ESTIMATE

- âœ… Stage 0: 1 hour (COMPLETE)
- âœ… Stage 1: 3 hours (COMPLETE) 
- ğŸ¯ Stage 2: 4-5 hours (NEXT - Browser control)
- Stage 3: 3-4 hours (Integration & Menu bar)
- Stage 4: 4-5 hours (Polish & UX)
- Stage 5: 3-4 hours (Landing page)
- Testing & Polish: 2-3 hours

**Remaining: 16-21 hours** (2-3 days of focused work)
**Completed: 4 hours** (Stages 0 & 1)

---

## ğŸš€ CURRENT STATUS & NEXT STEPS

### âœ… What's Working Now:
- **Maya AI Assistant**: Responds to "Hey Maya" consistently
- **Whisper Recognition**: High-accuracy offline speech processing
- **Samantha Voice**: Natural text-to-speech feedback  
- **Factory System**: Automatic best-engine selection
- **Comprehensive Testing**: Multiple validation scripts
- **Stable System**: Reverted from problematic enhanced features

### ğŸ¯ Immediate Next Step:
**Stage 2: Command Parser & Browser Control**

### Test First or Proceed?
**Recommendation**: Quick 2-minute test, then proceed:

```bash
# Quick verification Maya is working
python3 test_original_maya.py

# If Maya responds to "Hey Maya" properly, proceed to Stage 2
# If not, debug Stage 1 first
```

### How to Proceed with Goose:
1. **Test current system**: Run the test above
2. **If working**: "Let's start Stage 2 - Command Parser & Browser Control"  
3. **If issues**: "Maya test failed with [specific error], please fix before Stage 2"

The voice foundation is solid - time to add browser control! ğŸš€
